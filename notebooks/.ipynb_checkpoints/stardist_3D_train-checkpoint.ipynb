{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbd88f2-2827-4c48-b1da-76ac9c07dbf6",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f10883-173c-408d-943f-5626045f0b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 14:37:08.929245: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 14:37:09.151122: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-02 14:37:09.206812: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-02 14:37:10.204980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64 :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-02 14:37:10.205133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64 :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-02 14:37:10.205145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist import Rays_GoldenSpiral\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config3D, StarDist3D, StarDistData3D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6453dc7-e6a2-44e0-93ca-db01affc3135",
   "metadata": {},
   "source": [
    "### Import and Preprocess Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedcf7bb-a7bb-415a-8448-609e9f2c7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to the image files and masks\n",
    "root = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/stardist_training'\n",
    "img_dir = 'train/images'\n",
    "mask_dir = 'train/masks'\n",
    "\n",
    "X = sorted(glob(os.path.join(root, img_dir, '*.tif')))\n",
    "Y = sorted(glob(os.path.join(root, mask_dir, '*.tif')))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a13ca5-54c4-4644-90e1-ef5b5917ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize datasets (normalization can dramatically effect segmentation)\n",
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "\n",
    "axis_norm = (0,1,2)   # normalize channels independently\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a52f1-2251-4d67-8261-08071cf4d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b37ab-fe49-4fbf-8bbb-4b18bab29cd6",
   "metadata": {},
   "source": [
    "### Plot Example of Image and Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be36af9-6004-4a8f-9f1f-975de0a36c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to shoe an XY slice of raw and mask image\n",
    "def plot_img_label(img, lbl, img_title=\"image (XY slice)\", lbl_title=\"label (XY slice)\", z=None, **kwargs):\n",
    "    if z is None:\n",
    "        z = img.shape[0] // 2    \n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img[z], cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl[z], cmap=lbl_cmap)\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "i = 2\n",
    "img, lbl = X[i], Y[i]\n",
    "img = img if img.ndim==3 else img[...,:3]\n",
    "plot_img_label(img,lbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98868b86-b7d2-4108-bfe4-7cc351864a39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configure and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c686d-2d90-4500-b480-f582f5e1125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate anisotropy. Should be (2.0, 1.8, 1.8) for SmartSpim data\n",
    "extents = calculate_extents(Y)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddecd2b-fefc-4a15-94ff-646908f68aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get total memory for allocation\n",
    "import subprocess as sp\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "\n",
    "# Parameterize model\n",
    "n_rays = 96\n",
    "n_channel = 1\n",
    "use_gpu = True\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "\n",
    "# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "conf = Config3D (\n",
    "    rays             = rays,\n",
    "    grid             = grid,\n",
    "    anisotropy       = anisotropy,\n",
    "    use_gpu          = use_gpu,\n",
    "    n_channel_in     = n_channel,\n",
    "    # adjust for your data below (make patch size as large as possible)\n",
    "    train_patch_size = (16,32,32),\n",
    "    train_batch_size = 2,\n",
    ")\n",
    "\n",
    "# parameterize gpu usage\n",
    "if use_gpu:\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "    gpu_mem = get_gpu_memory()\n",
    "    limit_gpu_memory(0.8, total_memory = gpu_mem[0])\n",
    "    # alternatively, try this:\n",
    "    # limit_gpu_memory(None, allow_growth=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e8eda-9189-405b-b515-4619dd626761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and test parameters\n",
    "model_dir = os.path.join(root, 'models')\n",
    "model = StarDist3D(conf, name = 'stardist', basedir = model_dir)\n",
    "\n",
    "median_size = calculate_extents(Y, np.median)\n",
    "fov = np.array(model._axes_tile_overlap('ZYX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87960164-7d43-43f3-9b36-9bd4e7787695",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data = (X_val,Y_val), augmenter = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6cfbd6-4324-48f2-9e4b-7c3659d8f714",
   "metadata": {},
   "source": [
    "### Optimize Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57184481-b790-4c2c-ad40-a36cea68f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2766092-59c8-4166-81ff-fd9ed10a66be",
   "metadata": {},
   "source": [
    "### Segmentation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b5337-4ddf-4ab7-900a-b9871a799ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039a3bc-7341-45b2-8880-85125cc57e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot istance of image along with mask and prediction\n",
    "plot_img_label(X_val[0],Y_val[0], lbl_title=\"label GT (XY slice)\")\n",
    "plot_img_label(X_val[0],Y_val_pred[0], lbl_title=\"label Pred (XY slice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec36218-60dd-468b-a716-0120b92b379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics across range of IOU values\n",
    "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f256f5-19ba-485c-b385-797c93043454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prediction metrics across IOU values\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efde66-8260-4639-8838-2739fd715058",
   "metadata": {},
   "source": [
    "### Import Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d4a527-48db-454f-93c6-1c7d7118fa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled annotation data for block 4: 2168 cells and 0 noncells.\n",
      "Pulled annotation data for block 1: 1751 cells and 2 noncells.\n",
      "Pulled annotation data for block 3: 410 cells and 5 noncells.\n",
      "Pulled annotation data for block 2: 1641 cells and 2 noncells.\n"
     ]
    }
   ],
   "source": [
    "# Get annotated data and image file paths\n",
    "import re\n",
    "import os\n",
    "\n",
    "import utils.preprocess as pp\n",
    "import utils.evaluate as evaluate\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "base_dir = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/images/annotated'\n",
    "output_root = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/stardist_output'\n",
    "\n",
    "# create output directory if it doesn't already exist\n",
    "if not os.path.exists(output_root):\n",
    "    os.mkdir(output_root)\n",
    "\n",
    "blocks = defaultdict(dict)\n",
    "\n",
    "# loop through base directory and collect all data from \"block_#\" subfolders\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    if 'block' in root: \n",
    "        for file in files:\n",
    "            try:\n",
    "                block_num = re.findall('[0-9]', file)[0]\n",
    "            except:\n",
    "                continue\n",
    "            if 'signal' in file:\n",
    "                blocks[block_num]['signal'] = os.path.join(root, file)\n",
    "            elif 'background' in file:\n",
    "                blocks[block_num]['background'] = os.path.join(root, file)\n",
    "            elif 'detect' in file:\n",
    "                blocks[block_num]['detect'] = pp.get_locations(os.path.join(root, file))\n",
    "            else:\n",
    "                blocks[block_num]['reject'] = pp.get_locations(os.path.join(root, file))\n",
    "\n",
    "# print info on blocks        \n",
    "for key in blocks.keys():\n",
    "    try:\n",
    "        rejected = len(blocks[key]['reject'])\n",
    "    except:\n",
    "        rejected = 0\n",
    "    print('Pulled annotation data for block {0}: {1} cells and {2} noncells.'.format(str(key), len(blocks[key]['detect']), rejected))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ce7eb-0c2a-4e4b-9005-1c8dba1313a3",
   "metadata": {},
   "source": [
    "### Import Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c8c244-ef08-4256-a7e0-d5f26fbe9600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 14:37:27.470416: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 14:37:29.120173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2772 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "2022-12-02 14:37:29.120957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6656 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.503434, nms_thresh=0.4.\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/stardist_training/models'\n",
    "model = StarDist3D(None, name= 'stardist', basedir = model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5f085-880c-473c-a475-d83f654401dc",
   "metadata": {},
   "source": [
    "### Run Trained Model on Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ea6702-ba3e-4f0c-8b1f-8e4879a72e25",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:48:20.168930: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2022-12-01 15:48:20.169013: E tensorflow/stream_executor/cuda/cuda_dnn.cc:398] Possibly insufficient driver version: 515.86.1\n",
      "2022-12-01 15:48:20.169066: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops_3d.cc:509 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv3d/Conv3D' defined at (most recent call last):\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16269/705827369.py\", line 29, in <module>\n      Y_val_pred = model.predict_instances(img_norm, n_tiles=model._guess_n_tiles(img), show_tile_progress=False)[0]\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 775, in predict_instances\n      for r in self._predict_instances_generator(*args, **kwargs):\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 727, in _predict_instances_generator\n      for res in self._predict_sparse_generator(img, axes=axes, normalizer=normalizer, n_tiles=n_tiles,\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 549, in _predict_sparse_generator\n      tile_generator, output_shape, create_empty_output = tiling_setup()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 405, in tiling_setup\n      axes_net_tile_overlaps = self._axes_tile_overlap(axes_net)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 1084, in _axes_tile_overlap\n      self._tile_overlap = self._compute_receptive_field()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 1069, in _compute_receptive_field\n      y  = self.keras_model.predict(x)[0][0,...,0]\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv3d/Conv3D'\nDNN library is not found.\n\t [[{{node model/conv3d/Conv3D}}]] [Op:__inference_predict_function_867]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16269/705827369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mimg_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m99.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mY_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guess_n_tiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_tile_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# get centroids from masks. see: https://github.com/MouseLand/cellpose/issues/337\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\u001b[0m in \u001b[0;36mpredict_instances\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;31m# return last \"yield\"ed value of generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_instances_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\u001b[0m in \u001b[0;36m_predict_instances_generator\u001b[0;34m(self, img, axes, normalizer, sparse, prob_thresh, nms_thresh, scale, n_tiles, show_tile_progress, verbose, return_labels, predict_kwargs, nms_kwargs, overlap_label, return_predict)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             for res in self._predict_sparse_generator(img, axes=axes, normalizer=normalizer, n_tiles=n_tiles,\n\u001b[0m\u001b[1;32m    728\u001b[0m                                                       prob_thresh=prob_thresh, show_tile_progress=show_tile_progress, **predict_kwargs):\n\u001b[1;32m    729\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\u001b[0m in \u001b[0;36m_predict_sparse_generator\u001b[0;34m(self, img, prob_thresh, axes, normalizer, n_tiles, show_tile_progress, b, **predict_kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[0mtile_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_empty_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiling_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\u001b[0m in \u001b[0;36mtiling_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mtiling_axes\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0maxes_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# axes eligible for tiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mx_tiling_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtiling_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# numerical axis ids for x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0maxes_net_tile_overlaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_tile_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;31m# hack: permute tiling axis in the same way as img -> x was permuted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_n_tiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_permute_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\u001b[0m in \u001b[0;36m_axes_tile_overlap\u001b[0;34m(self, query_axes)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tile_overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tile_overlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_receptive_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m         overlap = dict(zip(\n\u001b[1;32m   1086\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\u001b[0m in \u001b[0;36m_compute_receptive_field\u001b[0;34m(self, img_size)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/segment_compare/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv3d/Conv3D' defined at (most recent call last):\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16269/705827369.py\", line 29, in <module>\n      Y_val_pred = model.predict_instances(img_norm, n_tiles=model._guess_n_tiles(img), show_tile_progress=False)[0]\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 775, in predict_instances\n      for r in self._predict_instances_generator(*args, **kwargs):\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 727, in _predict_instances_generator\n      for res in self._predict_sparse_generator(img, axes=axes, normalizer=normalizer, n_tiles=n_tiles,\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 549, in _predict_sparse_generator\n      tile_generator, output_shape, create_empty_output = tiling_setup()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 405, in tiling_setup\n      axes_net_tile_overlaps = self._axes_tile_overlap(axes_net)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 1084, in _axes_tile_overlap\n      self._tile_overlap = self._compute_receptive_field()\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/stardist/models/base.py\", line 1069, in _compute_receptive_field\n      y  = self.keras_model.predict(x)[0][0,...,0]\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/elyse/miniconda3/envs/segment_compare/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv3d/Conv3D'\nDNN library is not found.\n\t [[{{node model/conv3d/Conv3D}}]] [Op:__inference_predict_function_867]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import skimage.io\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "# Parameterize model\n",
    "n_rays = 96\n",
    "n_channel = 1\n",
    "use_gpu = True\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "\n",
    "# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "# model configuratons\n",
    "conf = Config3D (\n",
    "    rays             = rays,\n",
    "    grid             = grid,\n",
    "    anisotropy       = anisotropy,\n",
    "    use_gpu          = use_gpu,\n",
    "    n_channel_in     = n_channel,\n",
    "    # adjust for your data below (make patch size as large as possible)\n",
    "    train_patch_size = (16,32,32),\n",
    "    train_batch_size = 2,\n",
    ")\n",
    "\n",
    "\n",
    "# model parameters\n",
    "chs = ['signal', 'background']\n",
    "method = 'stardist'\n",
    "detect_times = defaultdict(int)\n",
    "axis_norm = (0,1,2)   # normalize channels independently\n",
    "\n",
    "#preprocessing parameters\n",
    "bkg_sub = True\n",
    "estimator = 'SExtractorBackground'\n",
    "pad = 50\n",
    "\n",
    "start_detect = time.time()\n",
    "for key in blocks.keys():\n",
    "        for ch in chs:\n",
    "            fname = os.path.basename(blocks[key][ch])[:-4]\n",
    "            img = skimage.io.imread(blocks[key][ch])\n",
    "            \n",
    "            if bkg_sub:\n",
    "                img = pp.astro_preprocess(img, estimator, pad = pad)\n",
    "            \n",
    "            # need top normalize. will send warning if you forget\n",
    "            img_norm = normalize(img,1,99.8,axis=axis_norm)\n",
    "            \n",
    "            Y_val_pred = model.predict_instances(img_norm, n_tiles=model._guess_n_tiles(img), show_tile_progress=False)[0]\n",
    "\n",
    "            # get centroids from masks. see: https://github.com/MouseLand/cellpose/issues/337\n",
    "            centroids = []\n",
    "            candidates = regionprops(Y_val_pred)\n",
    "            for c in range(len(candidates)):\n",
    "                location = [int(x) for x in candidates[c]['centroid']]\n",
    "                centroids.append(location[::-1])\n",
    "        \n",
    "            if ch == 'signal':\n",
    "                blocks[key]['pred_detect_' + method] = centroids\n",
    "            else:\n",
    "                blocks[key]['pred_reject_' + method] = centroids\n",
    "            \n",
    "            # save masks and flows\n",
    "            output_file = os.path.join(output_root, 'block_' + key + '_mask.tif')\n",
    "            \n",
    "            # save masks as tif\n",
    "            print(Y_val_pred.shape)\n",
    "            skimage.io.imsave(output_file, Y_val_pred)\n",
    "\n",
    "detect_times[method] = time.time() - start_detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1eb8e-dd8e-480b-baaf-91e5ec8b6772",
   "metadata": {},
   "source": [
    "### Stardist Outputs and Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93be215-5c2e-49c2-98cd-3e60f22e5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time to run each method\n",
    "for method in ['stardist']:\n",
    "    print('Using ' + method + ' method for 2D to 3D')\n",
    "    for key in blocks.keys():\n",
    "        print('Classified {0} cells and {1} noncells for annocation block {2}.'.format(len(blocks[key]['pred_detect_' + method]), \n",
    "                                                                                       len(blocks[key]['pred_reject_' + method]), \n",
    "                                                                                       str(key)))\n",
    "\n",
    "    print('Detection and Classification via ' + method + ' took {0} seconds.\\n'.format(detect_times[method]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de829d6c-b29f-460b-b806-4519b3535543",
   "metadata": {},
   "source": [
    "### Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53d433-72b8-4d4a-be09-fda42d1615ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics on model performance and plot results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "methods = ['stardist']\n",
    "max_dist = 10\n",
    "trained = False\n",
    "get_keys = ['4']\n",
    "\n",
    "performance = evaluate.get_performance(blocks, methods, max_dist, trained, get_keys)\n",
    "evaluate.plot_performance(performance, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54c831-15d8-4a9a-9295-3ae2e07e1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Matrix Plots\n",
    "F1_scores = performance[2::3, :-1]\n",
    "opt_vals = np.unravel_index(np.argmax(F1_scores, axis=None), F1_scores.shape)\n",
    "metric_df = evaluate.annot_pred_overlap(blocks, opt_vals[0] + 1, methods[opt_vals[1]])\n",
    "\n",
    "evaluate.plot_cm(metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fb514-14b8-486a-8001-f2e180693cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
