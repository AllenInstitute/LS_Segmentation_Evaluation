{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b2225-343c-411b-b5f4-3100799c1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pathways and initialize model\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "from cellpose import models, core, io\n",
    "\n",
    "# set pathways to test files\n",
    "# Paths to annotated test data\n",
    "base_dir = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/images/'\n",
    "output_root = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/cellpose_train'\n",
    "\n",
    "# create output directory if it doesn't already exist\n",
    "if not os.path.exists(output_root):\n",
    "    os.mkdir(output_root)\n",
    "\n",
    "# have cellpose log run\n",
    "io.logger_setup()\n",
    "\n",
    "# initialize model\n",
    "use_GPU = core.use_gpu()\n",
    "model = models.CellposeModel(gpu = use_GPU, model_type = 'nuclei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0ccaa-707b-4257-99fe-26a1e70f0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom functions\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from pycm import ConfusionMatrix\n",
    "\n",
    "\n",
    "# function to turn .xml files into x, y, z coordinates\n",
    "def get_locations(path):\n",
    "    # read xml file\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.read()\n",
    "    # get xml data in iterable format\n",
    "    markers = BeautifulSoup(data, features='xml').find_all('Marker')\n",
    "    cell_loci = []\n",
    "    # iterate and output marker locations\n",
    "    for marker in markers:\n",
    "        coords = re.findall('[0-9]+', marker.text)\n",
    "        coords = [int(x) for x in coords]\n",
    "        cell_loci.append(coords)\n",
    "    \n",
    "    return cell_loci\n",
    "\n",
    "# prediction and annotation overlap and build dataframe for validation metrics\n",
    "# max distance a prediction can be off and still count as cell. very conservative at 1 px\n",
    "def annot_pred_overlap(blocks, max_dist, type_2D, train = False, get_keys = []):\n",
    "\n",
    "    metric_df = pd.DataFrame(columns = ['x', 'y', 'z', 'block', 'annotated', 'predicted', 'mask_id'])\n",
    "    \n",
    "    if train:\n",
    "        type_key = ['train_detect_', 'train_reject_']\n",
    "    else:\n",
    "        type_key = ['pred_detect_', 'pred_detect_'] \n",
    "    \n",
    "    if len(get_keys) == 0:\n",
    "        key_list = list(blocks.keys())\n",
    "    else:\n",
    "        key_list = get_keys\n",
    "    \n",
    "    for key in key_list:\n",
    "    \n",
    "        # get annotated data (not always a reject file)\n",
    "        annot_detect = np.asarray(blocks[key]['detect'])\n",
    "            \n",
    "        try:\n",
    "            annot_reject = np.asarray(blocks[key]['reject'])\n",
    "            type_reject = np.ones((len(annot_reject), 1)) * 2\n",
    "        \n",
    "            annot_points = np.concatenate((annot_detect, annot_reject), axis = 0)\n",
    "            annot_types = np.concatenate((np.ones((len(annot_detect), 1)),\n",
    "                                          np.ones((len(annot_reject), 1)) * 2), axis = 0)\n",
    "        except:\n",
    "            annot_points = annot_detect.copy()\n",
    "            annot_types = np.ones((len(annot_detect), 1))\n",
    "\n",
    "        # get predicted data\n",
    "        pred_detect = np.asarray(blocks[key][type_key[0] + type_2D])\n",
    "        pred_reject = np.asarray(blocks[key][type_key[1] + type_2D])\n",
    "        \n",
    "        detect_mask = np.asarray(blocks[key][type_key[0] + type_2D + '_mask'])\n",
    "        reject_mask = np.asarray(blocks[key][type_key[1] + type_2D + '_mask'])\n",
    "    \n",
    "        if len(pred_reject) > 0:\n",
    "            pred_points = np.concatenate((pred_detect, pred_reject), axis = 0)\n",
    "            pred_types = np.concatenate((np.ones((len(pred_detect), 1)),\n",
    "                                         np.ones((len(pred_reject), 1)) * 2), axis = 0)\n",
    "            \n",
    "            masks = np.concatenate((detect_mask,\n",
    "                                   reject_mask), axis = 0)\n",
    "        else:\n",
    "            pred_points = pred_detect.copy()\n",
    "            pred_types = np.ones((len(pred_detect), 1))\n",
    "            \n",
    "            masks = detect_mask.copy()\n",
    "        \n",
    "        # create annotation and prediction tree for comparison\n",
    "        annot_tree = KDTree(annot_points)\n",
    "        pred_tree = KDTree(pred_points)\n",
    "    \n",
    "        # returns: for each element in annot_tree[i], indexes[i] is a list of indecies within distance r from pred_tree\n",
    "        indexes = annot_tree.query_ball_tree(pred_tree, r = max_dist)\n",
    "        pred_id = np.zeros((len(annot_types), 1))\n",
    "        mask_id = np.zeros((len(annot_types), 1))\n",
    "        pred_extra = np.zeros((len(pred_types), 1))\n",
    "    \n",
    "        # get the index and type for all annotated cells and id predicted cells that were not annotated\n",
    "        for c, idx in enumerate(indexes):\n",
    "            if len(idx) > 0:\n",
    "                pred_id[c] = pred_types[idx[0]]\n",
    "                mask_id[c] = masks[idx[0]]\n",
    "                pred_extra[idx[0]] = 1\n",
    "    \n",
    "        pred_id[pred_id == 0] = 3\n",
    "        data_array = np.concatenate((annot_points,\n",
    "                                    np.ones((len(annot_points), 1)) * int(key),\n",
    "                                    annot_types,\n",
    "                                    pred_id,\n",
    "                                    mask_id), axis = 1)\n",
    "    \n",
    "        # get location and type of predicted cells that where not annotated\n",
    "        pred_extra_loc, _ = np.where(pred_extra == 0)\n",
    "        if len(pred_extra_loc) > 0:\n",
    "            curr_points = pred_points[pred_extra_loc[:], :]\n",
    "            curr_types = pred_types[pred_extra_loc[:], :]\n",
    "            pred_array = np.concatenate((curr_points,\n",
    "                                        np.ones((len(curr_points), 1)) * int(key),\n",
    "                                        np.ones((len(curr_points), 1)) * 3,\n",
    "                                        curr_types,\n",
    "                                        np.zeros((len(curr_points), 1))), axis = 1)\n",
    "        \n",
    "            # add to annot array\n",
    "            data_array = np.vstack((data_array, pred_array))\n",
    "\n",
    "        # create dataframes                                         \n",
    "        curr_df = pd.DataFrame(data_array, columns = ['x', 'y', 'z', 'block', 'annotated', 'predicted', 'mask_id'])\n",
    "        metric_df = pd.concat((metric_df, curr_df))\n",
    "    return metric_df\n",
    "\n",
    "# Identify prediction and annotation overlap and build dataframe for validation metrics\n",
    "# Key: 1: signal that is detected and considered to be a cell\n",
    "#      2: signal that is detected but found to be noise and rejected\n",
    "#      3: singal that is annotated but not predicted to be signal\n",
    "def get_performance(data, method, trained, get_keys = []):\n",
    "    #since using different algorithm more flexibility in distance may be needed\n",
    "    perf_metrics = []\n",
    "\n",
    "    for i in range(10):\n",
    "        dist = i + 1\n",
    "        flow_df = annot_pred_overlap(data, dist, method, trained, get_keys)\n",
    "        cm_flow = ConfusionMatrix(flow_df['annotated'].values, flow_df['predicted'].values, classes = [1.0, 2.0, 3.0])\n",
    "        perf_metrics.extend([[cm_flow.class_stat['PPV'][1.0], dist],\n",
    "                            [cm_flow.class_stat['TPR'][1.0], dist],\n",
    "                            [cm_flow.class_stat['F1'][1.0], dist]])\n",
    "\n",
    "    # ignores numpy.where() warning\n",
    "    warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "    performance = np.asarray(perf_metrics)\n",
    "    performance = np.where(performance == 'None', 0, performance)\n",
    "    return performance\n",
    "\n",
    "# plots the performance of the flow model as the distance from annotated centroid is varied\n",
    "def plot_performance(performance):\n",
    "    colors = ['r', 'g', 'b']\n",
    "    mets = ['Percision', 'Recall', 'F1 Score']\n",
    "\n",
    "    opt_flow = np.argmax(performance[2::3, 0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (4, 4))\n",
    "    fig.suptitle('Distance between annotated and predicted Cell')\n",
    "\n",
    "    for i in range(3):\n",
    "        sns.lineplot(x = performance[i::3, 1], y = performance[i::3, 0], color = colors[i], label = mets[i], ax = ax, zorder = i+2)\n",
    "        ax.set_xlabel('Max distance (px)')\n",
    "        ax.set_ylabel('Metric score')\n",
    "        ax.set_title(method + ' detection')\n",
    "        ax.set_ylim(0.2, 1)\n",
    "    \n",
    "        ax.axvline(x = performance[2::3, 1][opt_flow], color = 'k', linestyle = '--', zorder = 1)\n",
    "\n",
    "        \n",
    "    sns.despine()\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    print('Top F1 Scores for flow detection: {0}'.format(performance[2::3, 0][opt_flow]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5d4f0-39f6-4996-9a0c-ebd53f3c8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get annotated data and image file paths\n",
    "blocks = defaultdict(dict)\n",
    "\n",
    "# loop through base directory and collect all data from \"block_#\" subfolders\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    if 'block' in root: \n",
    "        for file in files:\n",
    "            block_num = re.findall('[0-9]', file)[0]\n",
    "            if 'signal' in file:\n",
    "                blocks[block_num]['signal'] = os.path.join(root, file)\n",
    "            elif 'background' in file:\n",
    "                blocks[block_num]['background'] = os.path.join(root, file)\n",
    "            elif 'detect' in file:\n",
    "                blocks[block_num]['detect'] = get_locations(os.path.join(root, file))\n",
    "            else:\n",
    "                blocks[block_num]['reject'] = get_locations(os.path.join(root, file))\n",
    "\n",
    "# print info on blocks        \n",
    "for key in blocks.keys():\n",
    "    try:\n",
    "        rejected = len(blocks[key]['reject'])\n",
    "    except:\n",
    "        rejected = 0\n",
    "    print('Pulled annotation data for block {0}: {1} cells and {2} noncells.'.format(str(key), len(blocks[key]['detect']), rejected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27efacc-7e2c-4e03-823a-ea936c11a546",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There are 3 ways to run 3D Cellpose. The first 2 are exrapolating 2D to 3D\n",
    "# The Third way is using new Cellpose3D repo in other script\n",
    "import skimage.io\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "# Set parameters\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "channels = [0,0]\n",
    "prob_thresh = 0.9\n",
    "stitch_thresh = 0.5\n",
    "diameter = 9 # unit = px\n",
    "min_size = 60\n",
    "detect_times = defaultdict(int)\n",
    "method = 'flow'\n",
    "\n",
    "start_detect = time.time()\n",
    "for key in blocks.keys():\n",
    "    for ch in ['signal', 'background']:\n",
    "        fname = os.path.basename(blocks[key][ch])[:-4]\n",
    "        img = skimage.io.imread(blocks[key][ch])\n",
    "        \n",
    "        print(fname)\n",
    "            \n",
    "        if method == 'flow':\n",
    "            masks, flows, styles = model.eval(img, channels = channels, diameter = diameter, cellprob_threshold = prob_thresh, \n",
    "                                                         do_3D = True, min_size = min_size)\n",
    "        elif method == 'stitch':\n",
    "            masks, flows, styles = model.eval(img, channels = channels, diameter = diameter, cellprob_threshold = prob_thresh, \n",
    "                                                         do_3D = False, stitch_threshold = stitch_thresh)\n",
    "\n",
    "        # get centroids from masks. see: https://github.com/MouseLand/cellpose/issues/337\n",
    "        centroids = []\n",
    "        mask_num = []\n",
    "        candidates = regionprops(masks)\n",
    "        for c in range(len(candidates)):\n",
    "            location = [int(x) for x in candidates[c]['centroid']]\n",
    "            centroids.append(location[::-1])\n",
    "            mask_num.append(masks[location[0], location[1], location[2]])\n",
    "        \n",
    "        if ch == 'signal':\n",
    "            blocks[key]['pred_detect_' + method] = centroids\n",
    "            blocks[key]['pred_detect_' + method + '_mask'] = mask_num\n",
    "        else:\n",
    "            blocks[key]['pred_reject_' + method] = centroids\n",
    "            blocks[key]['pred_reject_' + method + '_mask'] = mask_num\n",
    "            \n",
    "        # save masks and flows\n",
    "        output_path = os.path.join(output_root, method)\n",
    "\n",
    "        # create output directory if it doesn't already exist\n",
    "        if not os.path.exists(output_path):\n",
    "            os.mkdir(output_path)\n",
    "            \n",
    "        # save masks as tif \n",
    "        io.save_masks(img, masks, flows, blocks[key][ch], png = False, tif = True, channels = channels, \n",
    "                      save_flows = True, save_outlines = True, savedir = output_path)\n",
    "            \n",
    "        # save all data for plotting\n",
    "        io.masks_flows_to_seg(img, masks, flows, diams, os.path.join(output_path, fname), channels=None)\n",
    "\n",
    "detect_times[method] = time.time() - start_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea5135-c71b-42eb-af72-b145641f99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time to run each method\n",
    "for method in ['flow']:\n",
    "    print('Using ' + method + ' method for 2D to 3D')\n",
    "    for key in blocks.keys():\n",
    "        print('Classified {0} cells and {1} noncells for annocation block {2}.'.format(len(blocks[key]['pred_detect_' + method]), \n",
    "                                                                                       len(blocks[key]['pred_reject_' + method]), \n",
    "                                                                                       str(key)))\n",
    "\n",
    "    print('Detection and Classification via ' + method + ' took {0} seconds.\\n'.format(detect_times[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a018639-9eca-4b97-a2d0-ddf5abf510ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics on model performance and plot results\n",
    "method = 'flow'\n",
    "trained = False\n",
    "\n",
    "performance = get_performance(blocks, method, trained)\n",
    "plot_performance(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25334b73-314a-4436-8a6e-b50aa250ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e48c3d-36a3-42a2-aa8a-b2bc780556a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model using only cells with centroids within N number of px away from annotation\n",
    "dist = 1\n",
    "\n",
    "flow_df = annot_pred_overlap(blocks, dist, 'flow')\n",
    "train_ids = flow_df.loc[(flow_df['annotated'] == 1.0) & (flow_df['predicted'] == 1), ['mask_id']].values\n",
    "train_ids = np.unique(train_ids)\n",
    "\n",
    "# load image and mask data for block 4\n",
    "mask_path = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/cellpose_train/flow/block_4_signal_seg.npy'\n",
    "model_path = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/cellpose_train/model'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "\n",
    "# keep only masks that are withing the alotted threshold \n",
    "seg_file = np.load(mask_path, allow_pickle = True).item()\n",
    "mask_array = seg_file['masks']\n",
    "mask_array = np.where(np.isin(mask_array, train_ids), mask_array, 0)\n",
    "train_array = skimage.io.imread(blocks['4']['signal'])\n",
    "\n",
    "#verify that the number of identified masks is the same as in the masked array\n",
    "print('{0} cells identified within {1} px of annotated cells. Mask array contains {2} unique masks.'.format(len(train_ids), \n",
    "                                                                                                            dist, \n",
    "                                                                                                            len(np.unique(mask_array))))\n",
    "\n",
    "# format needs to be list of arrays with shape (nchan x Ly x Lx)\n",
    "train_imgs = [np.expand_dims(train_array[img, :, :], axis = 0) for img in range(train_array.shape[0])]\n",
    "train_masks = [np.expand_dims(mask_array[mask, :, :], axis = 0) for mask in range(mask_array.shape[0])]\n",
    "\n",
    "\n",
    "model.train(train_data = train_imgs, train_labels = train_masks, channels = [0, 0],\n",
    "            save_path = model_path, model_name = 'block_4_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e9448-5f7d-4ce7-b264-386d6089b922",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rerun with Trained Model: only did block 4\n",
    "model_path = '/home/elyse/Documents/GitHub/LS_evaluation_tool/test_data/cellpose_train/models/block_4_model'\n",
    "model_trained = models.CellposeModel(gpu = use_GPU, pretrained_model = model_path)\n",
    "\n",
    "channels = [0,0]\n",
    "prob_thresh = 0.0\n",
    "diameter = 5 # unit = px\n",
    "min_size = 10\n",
    "detect_times = defaultdict(int)\n",
    "method = 'flow'\n",
    "key_root = ['train_detect_', 'train_reject_'] \n",
    "\n",
    "for kr, ch in enumerate(['signal', 'background']):\n",
    "    fname = os.path.basename(blocks['4'][ch])[:-4] + '_trained'\n",
    "    img = skimage.io.imread(blocks['4'][ch])\n",
    "\n",
    "    masks, flows, styles = model_trained.eval(img, channels = channels, diameter = diameter, cellprob_threshold = prob_thresh, \n",
    "                                              do_3D = True, min_size = min_size)\n",
    "    \n",
    "    # get centroids from masks. see: https://github.com/MouseLand/cellpose/issues/337\n",
    "    centroids = []\n",
    "    mask_num = []\n",
    "    candidates = regionprops(masks)\n",
    "    for c in range(len(candidates)):\n",
    "        location = [int(x) for x in candidates[c]['centroid']]\n",
    "        centroids.append(location[::-1])\n",
    "        mask_num.append(masks[location[0], location[1], location[2]])\n",
    "        \n",
    "    blocks['4'][key_root[kr] + method] = centroids\n",
    "    blocks['4'][key_root[kr] + method + '_mask'] = mask_num\n",
    "            \n",
    "    # save masks and flows\n",
    "    output_path = os.path.join(output_root, method)\n",
    "\n",
    "    # create output directory if it doesn't already exist\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "            \n",
    "    # save masks as tif \n",
    "    io.save_masks(img, masks, flows, blocks['4'][ch], png = False, tif = True, channels = channels, \n",
    "                  save_flows = True, save_outlines = True, savedir = output_path)\n",
    "            \n",
    "    # save all data for plotting\n",
    "    io.masks_flows_to_seg(img, masks, flows, diams, os.path.join(output_path, fname), channels=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e4713-2c40-4dad-b13f-f96990bb7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time to run each method\n",
    "for method in ['flow']:\n",
    "    print('Using ' + method + ' method for 2D to 3D')\n",
    "    for key in ['4']:\n",
    "        print('Classified {0} cells and {1} noncells for annocation block {2}.'.format(len(blocks[key]['train_detect_' + method]), \n",
    "                                                                                       len(blocks[key]['train_reject_' + method]), \n",
    "                                                                                       str(key)))\n",
    "\n",
    "    print('Detection and Classification via ' + method + ' took {0} seconds.\\n'.format(detect_times[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146ab7e-5fb4-4ffb-b116-6779e1da19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics on model performance and plot results\n",
    "method = 'flow'\n",
    "trained = True\n",
    "get_keys = ['4']\n",
    "\n",
    "performance = get_performance(blocks, method, trained, get_keys)\n",
    "plot_performance(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
